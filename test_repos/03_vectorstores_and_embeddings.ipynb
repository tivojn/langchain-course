{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0d647f70",
      "metadata": {
        "id": "0d647f70"
      },
      "source": [
        "# Vectorstores and Embeddings\n",
        "\n",
        "Recall the overall workflow for retrieval augmented generation (RAG):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125247c2",
      "metadata": {
        "id": "125247c2"
      },
      "source": [
        "![overview.jpeg](attachment:overview.jpeg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7f8d2266-4a35-4904-ae9d-c89790c5ae61",
      "metadata": {
        "height": 166,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f8d2266-4a35-4904-ae9d-c89790c5ae61",
        "outputId": "185ee831-7ea2-4c75-cb53-1c05727ed48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "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\n",
            "total 302\n",
            "-rw------- 1 root root 186730 Jul  8 07:07 Stanley_Yao_Resume.pdf\n",
            "-rw------- 1 root root 121525 Jul  8 06:36 Gloria_Li_Resume.pdf\n"
          ]
        }
      ],
      "source": [
        "#!pip install openai langchain\n",
        "#!pip install tiktoken\n",
        "#!pip install python-dotenv\n",
        "import os\n",
        "import openai\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "#import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-R6lfhchOciFp2GQsBuaUT3BlbkFJAzQNN6ZiPqfkJeKFkff\"\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "print(openai.api_key)\n",
        "!cd /content/drive/MyDrive/python_colab_prj/langchain-course/docs;ls -lt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460a54b0",
      "metadata": {
        "id": "460a54b0"
      },
      "source": [
        "We just discussed `Document Loading` and `Splitting`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2437469e",
      "metadata": {
        "height": 234,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2437469e",
        "outputId": "c03d981d-790a-468e-8ce3-191417f4b121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.12.0-py3-none-any.whl (254 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/254.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/254.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.5/254.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf\"),\n",
        "    PyPDFLoader(\"/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b00227c4",
      "metadata": {
        "id": "b00227c4"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"docs/Gloria_Li_Resume.pdf\"),\n",
        "    PyPDFLoader(\"docs/Stanley_Yao_Resume.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "eb44bf0d",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "eb44bf0d"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b71e46cc",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "b71e46cc"
      },
      "outputs": [],
      "source": [
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e061f22d",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e061f22d",
        "outputId": "11b91cea-698b-4237-cf89-d16931586e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of splite is    len(splits): 8\n",
            "<class 'list'>\n",
            "[Document(page_content='Gloria Li  \\n+1 332.248.6208 | yl4661@columbia.edu  | linkedin.com/in/yutong -li-415780229    \\nEDUCATION  \\nColumbia University                                                                                                                      New York, NY \\nB.A. in Economics                                                                                                                       Expected May 2023  \\n• Cumulative GPA:  3.7/4.0；Honors: Dean ’s List（2021-2022） \\n• Relevant Coursework:  Econometrics  (A-), Java and programming  (A), Financial Economics  (A-), \\nCorporate Finance  (A), Statistics  (A) \\n• Standardized Test Score:  GRE 335/340  (Verbal Reasoning: 165, 95th percentile; Quantitative \\nReasoning:170, 96th percentile)  \\nLanguages:  Mandarin , English , Japanese  \\nTechnical Skills : SQL, Java, Excel, PowerPoint, Financial Modeling   \\n \\nPROFESSIONAL  EXPERIENCE  \\nArk Technology                                                                                                                              New York, NY \\nBusiness  Analyst                                                                                                           Dec 2020 - Oct 2022 \\n▪ Conducted  in-depth research and analysis with 1000+ survey samples  from designed survey  and 50+ \\ninterview samples  \\n▪ Compel led data gathered from various corporations’ financial reports using Tableau , enhanc ed project \\nefficiency by 25%', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0}), Document(page_content='interview samples  \\n▪ Compel led data gathered from various corporations’ financial reports using Tableau , enhanc ed project \\nefficiency by 25%  \\n▪ Fostered communication between stakeholders, engineering, operation, and marketing  to manage timeline s \\n▪ Develop ed milestones and facilitated internal collaboration , improved speeds of production circle by 30% \\nyear over year  \\n▪ Developed a road map for mobile U ser Generated Content platform, led a cross -functional product team, \\nmanage d prioritization and monitor ed the work to ensure whole -product readiness  \\n▪ Defin ed key performance metrics  such as click -through  rate and sign -on rate  by collaborating with C- level \\nsuite and key stakeholders to  improve methodologies across the company  \\n▪ Analy zed the performance of the mobile  User Generated Content platform , formed the report based on \\nchanges in users’ preferences  and forecast ed the trends to improve operations  \\n \\nChina Poly Group Surpass Commercial Corporation                                                                     Beijing, CN  \\nBusiness A nalyst Intern                                                                                                              May 2021 - Jul 2021  \\n▪ Evaluate d profits and summarized the insights  through  SQL  \\n▪ Visualized  and demoed quarterly financial reporting Tableau dashboards to different portfolio managers \\nand decision -makers , improv ed the campaign efficiency by 3%', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0}), Document(page_content='and decision -makers , improv ed the campaign efficiency by 3% \\n▪ Collaborated with senior manager to propose 5+ daily reports through Tableau on internal policies  to ensure \\nthe corporation’s wide compliance with domestic and internal trading and shipping requirements  \\n  \\nEXTRACURRICULAR ACTIVITIES  \\nGuanghua School of Management                                                                                                     Beijing, CN  \\nSummer Teaching Assistant                                                                                                       Jul 2021 - Aug 2021  \\n▪ Outlined  5 course structure by collecting past syllabus and intervie wing  professors and lecturers  \\n▪ Collected 20+ research papers and government policies to cater the tea ching goal of 9 classes on aspects of \\ncontemporary Chinese economy and market  \\n▪ Documented research procedures through  a series of detailed background researches including oil, wine, \\ngame industry, and science technology  \\n \\nMcKinsey & Company  Project                                                                                                           Beijing, CN  \\nData Analyst                                                                                                                               Jul 2020 - Aug 2020  \\n▪ Automated  data extraction process for seasonal revenue reporting by introducing SQL connector on Excel', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0}), Document(page_content='▪ Automated  data extraction process for seasonal revenue reporting by introducing SQL connector on Excel  \\n▪ Assisted  senior manager s to track and monitor the energy vehicle market share, cre ated a dashboard to \\npresent the insights to stakeholders  \\n▪ Documented process flow, scope, and responsibilities for data analysts thoughtfully  for future references   \\n▪ Collaborated  with marketing team to align  business strategies for external stakeholders ; optimized \\nprofitability and locating competitive advantages  \\n  \\nSKILLS & INTERESTS  \\n▪ Sports:  Equestrian Athlete; Certificated Eighth Level Rider of German Equestrian Federation', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0}), Document(page_content='Shicheng(Stanley) Yao +1 312.888.6692 | stan912@uchicago.edu | www.linkedin.com/in/stanley-yao-455872282   SKILLS Business and Economics: • Investment & Financial Analysis: Market researching, financial documents processing, competition and trend analyzing, assessing company health, and identifying growth opportunities.  • Relationship Management: Building and nurturing strong client relationships. Technology: • AI Application Development: Leveraging AI and large language models (LLMs) for enhanced decision-making. • Coding & Open-Source Development: Experience with Python, Node.js, and contributing to open-source projects via platforms like Github and Hugging Face. • Vector Database Management: Knowledgeable in embedding and querying vector databases via similarity search.  EXPERIENCE  AI Engineer Ourpalm Co., Ltd. | Beijing, China | June 2023 - Current (Top-tier mobile gaming company listed in ChiNext Index, stock quote: 300315) (Top tier mobile gaming company listed in ChiNext Index, stock quote: 300315) • Developed an in-depth understanding of Transformers and Neural Networks, applying Python programming skills to code for agent, memory, chains, and prompt templating using LangChain via API calls to LLMs like OpenAI. • Utilized open-source coding practices through platforms like Github and Huggingface. • Employed Vector DBs such as Pinecone, Chroma DB for embedding and querying via similarity searches. • Personal pilot AI project https://stan.cool (working in progress', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 0}), Document(page_content='such as Pinecone, Chroma DB for embedding and querying via similarity searches. • Personal pilot AI project https://stan.cool (working in progress and launch ETA late August, 2023 ) Stock Analyst Sponge Capital | Beijing, China | September 2021 - April 2022 (PE firm in Beijing managing ¥2 Billion equity) • Prepared investment materials and secured financing for investment deals. • Conducted in-depth analysis on 100+ corporations across various markets, providing investment recommendations to the executive team. • Delivered oral and written reports on general economic trends, individual corporations, and entire industries. • Valued and priced securities based on thorough analysis. • Contributed to quarterly close and monthly forecast processes. Game Designer  Laya Box | Beijing, Beijing, China  May 2021 - September 2021 (Provides largest H5 engine and developer community in China) • Supported game balance by analyzing statistics, virtual goods, economics, and user motivations. • Utilized live data and player feedback to optimize the game experience. • Developed game systems, individual gameplay features, and player progressions. • Presented reports to potential investors, securing an initial investment of 15 million dollars.   Commented [JQ1]: Skills 是为了让hr看一眼就明白的地方，写词汇就够了，不需要描述，最好写出具体的能力。比如Data Analysis：Statistical modeling (includes LLM, CNN, Regression, etc),  Python Jupyter Notebook, Pytorch, Big data, Cloud computing', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 0}), Document(page_content='Commented [JQ2]: Experience部分我的建议是每一个bullet point前半句是用了什么tools，做了什么。后半句是达到了什么样的outcome/achievement。并且最好要量化这个结果。比如说用了用pytorch train了xxx model，model的accuracy/roc达到了什么数字，最后这个model给你/公司带来了什么insights \\nCommented [JQ3]: 比如这句，就可以再往后写一下这个recommendation给team带来了什么影响，怎么影响了他们的投资方向，公司的revenue有没有因此上升', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 0}), Document(page_content='EDUCATION   Bachelor of Arts (B.A.) - Business and Economics  University of Chicago, Chicago, Illinois   May 2025  \\n   Commented [JQ4]: 删减了skills之后如果还有字符，可以考虑在这个section加入上过哪些比较有用的课程，比如econometrics， finance之类的', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 1})]\n"
          ]
        }
      ],
      "source": [
        "print(f'''length of splite is    len(splits): {len(splits)}''')\n",
        "print(type(splits))\n",
        "print(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "848e26fd",
      "metadata": {
        "id": "848e26fd"
      },
      "source": [
        "## Embeddings\n",
        "\n",
        "Let's take our splits and embed them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d9dca7a8",
      "metadata": {
        "height": 47,
        "tags": [],
        "id": "d9dca7a8"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c4099521",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "c4099521"
      },
      "outputs": [],
      "source": [
        "sentence1 = \"i like dogs\"\n",
        "sentence2 = \"i like canines\"\n",
        "sentence3 = \"the weather is ugly outside\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d553549a",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "d553549a"
      },
      "outputs": [],
      "source": [
        "embedding1 = embedding.embed_query(sentence1)\n",
        "embedding2 = embedding.embed_query(sentence2)\n",
        "embedding3 = embedding.embed_query(sentence3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0cbe9a9e",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "0cbe9a9e"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "49fc0f8f",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fc0f8f",
        "outputId": "855b2c8e-97b1-4bf7-de1d-49ea43592b68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9631853877103518"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "np.dot(embedding1, embedding2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "32a1fac7",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32a1fac7",
        "outputId": "86ba3e13-72ca-49f0-fefa-766af5ad39d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7709997651294672"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "np.dot(embedding1, embedding3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9dd18328",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dd18328",
        "outputId": "1f754a0b-cd46-41e2-b15a-cf067e6c54fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7596334120325523"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "np.dot(embedding2, embedding3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fc7b24f",
      "metadata": {
        "id": "4fc7b24f"
      },
      "source": [
        "## Vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "da2213e6",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "da2213e6",
        "outputId": "5d01144a-4e91-4232-b420-6b3780f1942e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.3.26-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n",
            "Collecting requests>=2.28 (from chromadb)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.9)\n",
            "Collecting hnswlib>=0.7 (from chromadb)\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb)\n",
            "  Downloading clickhouse_connect-0.6.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (966 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m966.7/966.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.8.1)\n",
            "Collecting fastapi>=0.85.1 (from chromadb)\n",
            "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.6.3)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
            "Collecting importlib-metadata (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.16)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.85.1->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.7.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->clickhouse-connect>=0.5.7->chromadb) (3.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.1.1)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2119846 sha256=beabedf7182884764b2ed4cf97cdced5c9f555c2d5ee8a29c2778081e604747b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: tokenizers, monotonic, zstandard, websockets, uvloop, requests, pulsar-client, overrides, lz4, importlib-metadata, humanfriendly, httptools, hnswlib, h11, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, clickhouse-connect, onnxruntime, fastapi, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 chromadb-0.3.26 clickhouse-connect-0.6.6 coloredlogs-15.0.1 fastapi-0.100.0 h11-0.14.0 hnswlib-0.7.0 httptools-0.6.0 humanfriendly-10.0 importlib-metadata-6.8.0 lz4-4.3.2 monotonic-1.6 onnxruntime-1.15.1 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 requests-2.31.0 starlette-0.27.0 tokenizers-0.13.3 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 zstandard-0.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#!git clone https://github.com/nmslib/hnswlib.git\n",
        "#!cd ./hnswlib\n",
        "#!python setup.py install\n",
        "\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "201e6afa",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "201e6afa"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "93960ac5",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "93960ac5"
      },
      "outputs": [],
      "source": [
        "persist_directory = '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a195e72a",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "a195e72a"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/drive/MyDrive/python_colab_prj/langchain-course/docs/chroma  # remove old database files if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "690efd0a",
      "metadata": {
        "height": 98,
        "tags": [],
        "id": "690efd0a"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f777480c",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f777480c",
        "outputId": "ac59b772-7f4c-4b5f-cb4c-f15f37f0477e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efca7589",
      "metadata": {
        "id": "efca7589"
      },
      "source": [
        "### Similarity Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "3e20837d",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "3e20837d"
      },
      "outputs": [],
      "source": [
        "question = \"anything about Java programming?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f9bde572",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "f9bde572"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "41388af1",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41388af1",
        "outputId": "41b2e99c-be8c-40ea-af96-231a90a77702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "183434f6",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "183434f6",
        "outputId": "342fca1a-1dbe-4d88-e265-ca5eb1b1cf7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'such as Pinecone, Chroma DB for embedding and querying via similarity searches. • Personal pilot AI project https://stan.cool (working in progress and launch ETA late August, 2023 ) Stock Analyst Sponge Capital | Beijing, China | September 2021 - April 2022 (PE firm in Beijing managing ¥2 Billion equity) • Prepared investment materials and secured financing for investment deals. • Conducted in-depth analysis on 100+ corporations across various markets, providing investment recommendations to the executive team. • Delivered oral and written reports on general economic trends, individual corporations, and entire industries. • Valued and priced securities based on thorough analysis. • Contributed to quarterly close and monthly forecast processes. Game Designer  Laya Box | Beijing, Beijing, China  May 2021 - September 2021 (Provides largest H5 engine and developer community in China) • Supported game balance by analyzing statistics, virtual goods, economics, and user motivations. • Utilized live data and player feedback to optimize the game experience. • Developed game systems, individual gameplay features, and player progressions. • Presented reports to potential investors, securing an initial investment of 15 million dollars.   Commented [JQ1]: Skills 是为了让hr看一眼就明白的地方，写词汇就够了，不需要描述，最好写出具体的能力。比如Data Analysis：Statistical modeling (includes LLM, CNN, Regression, etc),  Python Jupyter Notebook, Pytorch, Big data, Cloud computing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edb21d8",
      "metadata": {
        "id": "1edb21d8"
      },
      "source": [
        "Let's save this so we can use it later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "ea657123",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "ea657123"
      },
      "outputs": [],
      "source": [
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cefe9f6a",
      "metadata": {
        "id": "cefe9f6a"
      },
      "source": [
        "## Failure modes\n",
        "\n",
        "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
        "\n",
        "But there are some failure modes that can creep up.\n",
        "\n",
        "Here are some edge cases that can arise - we'll fix them in the next class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "df0f29f9",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "df0f29f9"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about Experiences?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "02be97df",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "02be97df"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9f579e",
      "metadata": {
        "id": "2a9f579e"
      },
      "source": [
        "Notice that we're getting duplicate chunks (because of the duplicate `MachineLearning-Lecture01.pdf` in the index).\n",
        "\n",
        "Semantic search fetches all similar documents, but does not enforce diversity.\n",
        "\n",
        "`docs[0]` and `docs[1]` are indentical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d39f6954",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d39f6954",
        "outputId": "8c76312a-ee4d-4e68-d3e5-e35a0a49001c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Commented [JQ2]: Experience部分我的建议是每一个bullet point前半句是用了什么tools，做了什么。后半句是达到了什么样的outcome/achievement。并且最好要量化这个结果。比如说用了用pytorch train了xxx model，model的accuracy/roc达到了什么数字，最后这个model给你/公司带来了什么insights \\nCommented [JQ3]: 比如这句，就可以再往后写一下这个recommendation给team带来了什么影响，怎么影响了他们的投资方向，公司的revenue有没有因此上升', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "e04e3d1b",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e04e3d1b",
        "outputId": "7c9ac009-bf9e-495e-b808-c9c2fec778fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='interview samples  \\n▪ Compel led data gathered from various corporations’ financial reports using Tableau , enhanc ed project \\nefficiency by 25%  \\n▪ Fostered communication between stakeholders, engineering, operation, and marketing  to manage timeline s \\n▪ Develop ed milestones and facilitated internal collaboration , improved speeds of production circle by 30% \\nyear over year  \\n▪ Developed a road map for mobile U ser Generated Content platform, led a cross -functional product team, \\nmanage d prioritization and monitor ed the work to ensure whole -product readiness  \\n▪ Defin ed key performance metrics  such as click -through  rate and sign -on rate  by collaborating with C- level \\nsuite and key stakeholders to  improve methodologies across the company  \\n▪ Analy zed the performance of the mobile  User Generated Content platform , formed the report based on \\nchanges in users’ preferences  and forecast ed the trends to improve operations  \\n \\nChina Poly Group Surpass Commercial Corporation                                                                     Beijing, CN  \\nBusiness A nalyst Intern                                                                                                              May 2021 - Jul 2021  \\n▪ Evaluate d profits and summarized the insights  through  SQL  \\n▪ Visualized  and demoed quarterly financial reporting Tableau dashboards to different portfolio managers \\nand decision -makers , improv ed the campaign efficiency by 3%', metadata={'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "docs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a3a915d",
      "metadata": {
        "id": "3a3a915d"
      },
      "source": [
        "We can see a new failure mode.\n",
        "\n",
        "The question below asks a question about the third lecture, but includes results from other lectures as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "b19135e5",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "b19135e5"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about year of graduate?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "d434942c",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "d434942c"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "c2c5df59",
      "metadata": {
        "height": 47,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2c5df59",
        "outputId": "ad24f1e1-4af1-40fc-dad9-9f56ba0d7e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 1}\n",
            "{'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Gloria_Li_Resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 0}\n",
            "{'source': '/content/drive/MyDrive/python_colab_prj/langchain-course/docs/Stanley_Yao_Resume.pdf', 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "for doc in docs:\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "8e6cb50c",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6cb50c",
        "outputId": "4ba8e4a7-0df8-4b21-a71f-66d3aa5a7df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commented [JQ2]: Experience部分我的建议是每一个bullet point前半句是用了什么tools，做了什么。后半句是达到了什么样的outcome/achievement。并且最好要量化这个结果。比如说用了用pytorch train了xxx model，model的accuracy/roc达到了什么数字，最后这个model给你/公司带来了什么insights \n",
            "Commented [JQ3]: 比如这句，就可以再往后写一下这个recommendation给team带来了什么影响，怎么影响了他们的投资方向，公司的revenue有没有因此上升\n"
          ]
        }
      ],
      "source": [
        "print(docs[4].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3dbca56",
      "metadata": {
        "id": "c3dbca56"
      },
      "source": [
        "Approaches discussed in the next lecture can be used to address both!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cdc67ae-59e0-4a84-9fe6-e3a0391114d0",
      "metadata": {
        "height": 30,
        "id": "8cdc67ae-59e0-4a84-9fe6-e3a0391114d0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}